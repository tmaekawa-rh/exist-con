import sys
import os
import configparser
import requests
import pandas as pd
import xml.etree.ElementTree as ET
import hashlib
from io import StringIO
from datetime import datetime, timezone
from time import sleep

## Django Setup
import django
import pymysql
pymysql.install_as_MySQLdb()
conffile = os.path.join(os.path.dirname(__file__), "../../conf/insert2db.conf")
conf = configparser.SafeConfigParser()
conf.read(conffile)
sys.path.append(conf.get('exist', 'syspath'))
os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'intelligence.settings')
django.setup()
from apps.exploit.models import Exploit
import django.utils.timezone as tzone
from django.db import IntegrityError

## Logger Setup
from logging import getLogger, DEBUG, NullHandler
logger = getLogger(__name__)
logger.addHandler(NullHandler())
logger.setLevel(DEBUG)
logger.propagate = True

DataDir = os.path.join(os.path.dirname(__file__), '../data/')

class Tracker():
    def __init__(self):
        self.name = 'ExploitDB'
        self.ID = 111
        self.URL = 'https://www.exploit-db.com/rss.xml'
        self.DataFilePath = DataDir + 'exdb/rss.xml'
        self.header = [
            'title',
            'link',
            'description',
            'type',
            'pubDate',
            'guid',
        ]

    def fetchExdbText(self, guid):
        filepath = DataDir + "exdb/data/" + guid
        if not os.path.exists(filepath):
            url = "https://www.exploit-db.com/raw/{id}".format(id=guid)
            logger.info(url)
            headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko'}
            try:
                res = requests.get(url, headers=headers)
            except Exception as e:
                logger.error(e)
            if not res.text == '':
                open(filepath, 'w').write(res.text)
        if guid.endswith("pdf"):
            text = ''
        else:
            text = open(filepath).read()
        sleep(5)
        return text

    def makeDataFrame(self):
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko'}
        try:
            res = requests.get(self.URL, headers=headers)
        except Exception as e:
            logger.error(e)
        if not res.text == '':
            open(self.DataFilePath, 'w').write(res.text)
        xml_data = open(self.DataFilePath).read()
        root = ET.XML(xml_data)
        all_records = []
        for child in root[0]:
            if child.tag == 'item':
                record = {}
                for subchild in child:
                    record[subchild.tag] = subchild.text
                all_records.append(record)
        df = pd.DataFrame(all_records)
        return df

    def parse(self):
        logger.info("start parsing: %s", self.name)

        df = self.makeDataFrame()
        queries = []
        if df.empty:
            logger.info("no update")
            return queries

        for i, v in df.iterrows():
            guid = v.guid.split('/')[-1]
            line = str(self.ID) + ","
            line += str(v.values)
            md5 = hashlib.md5(line.encode('utf-8')).hexdigest()
            try:
                query = Exploit(
                    id = md5,
                    title = v.title,
                    description = v.description,
                    referrer = v.link,
                    datetime = datetime.strptime(v.pubDate, '%a, %d %b %Y %H:%M:%S +0000').replace(tzinfo=timezone.utc),
                    text = self.fetchExdbText(guid),
                    source = self.ID,
                )
            except Exception as e:
                logger.error("%s: %s", e, line)
            queries.append(query)

        logger.info("done parsing: %s, %s queries were parsed", self.name, len(queries))
        return queries
